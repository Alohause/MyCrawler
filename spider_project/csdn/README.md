# csdn.py

本项目是一个使用 Selenium 自动化控制浏览器爬取 CSDN 首页文章内容的脚本。爬取到的文章将自动转换为 Markdown 格式并保存在本地。

---

## 功能介绍
- 自动访问 CSDN 首页，滚动加载更多文章
- 智能识别文章列表容器和文章项
- 自动进入每篇文章详情页，提取正文内容
- 支持懒加载处理、解决乱码问题
- 将文章转换为 Markdown 格式保存至本地文件夹

---

## 使用方法
1. 安装依赖
- 请先确保你已经安装了以下 Python 库： `pip install selenium beautifulsoup4 parsel html2text`
2. 下载 ChromeDriver
- 请根据你的 Chrome 浏览器版本下载对应版本的 `ChromeDriver`
- 将其路径填写到脚本中的 `chromedriver_path`
3. 启动脚本
- 脚本将启动浏览器，自动滚动页面，提取文章内容，最终将文章以 .md 文件保存到 ./文件/ 目录中。

---

## 输出结构
所有文章将以 Markdown 文件形式保存于 ./文件/ 文件夹下,每个文件名对应文章标题，内容为文章正文，包含原始链接格式。

---

## 配置说明
- 自动滑动次数：脚本会向下滚动页面 15 次以加载更多文章
- 反检测设置：使用 CDP 指令规避 **navigator.webdriver** 检测
- 文章提取选择器：内置多种选择器以适配不同 CSDN 页面布局
- 正文选择器：支持文章内容的多种结构 *.article_content、.markdown_views、article.baidu_pl* 等

---

## 注意事项
- 如果文章结构发生变动，可根据实际页面结构调整选择器部分代码
- 建议在调试阶段去掉无头模式 (headless) 以观察页面行为

---

## 许可证
本项目仅供学习与研究使用，禁止用于任何违反法律法规的行为。

---

# 博客.py

CSDN 博客信息采集脚本，本项目是一个基于 _requests + pyquery_ 实现的轻量级爬虫，用于爬取指定 CSDN 用户的全部博客列表，并将文章信息（标题、发布日期、阅读数、评论数、链接）保存为 csv 文件。

---

## 功能简介
- 支持输入任意 CSDN 用户名爬取其博客
- 自动遍历分页，直到最后一页
- 自动识别文章发布时间、阅读数和评论数
- 数据保存为结构化 csv 文件，方便进一步分析

---

## 依赖环境
- 请确保已安装以下 Python 库： `pip install requests pyquery`

---

## 使用方法
1. 运行脚本
2. 按提示输入 CSDN 用户名：`请输入 CSDN ID: `，脚本会自动访问 url，并从第一页开始逐页爬取。

---

## 输出说明
- 输出文件名为：_csdn_articles.csv_
- 文件编码为 UTF-8-SIG，兼容 Excel 打开
- 数据格式如下：

|标题|日期|阅读数|评论数|链接|
|-------------|--|----|--|--|
|深度学习入门指南|2024-10-21|1234|45|(url)|

---

## 主要字段说明
|字段名|说明|
|--|---|
|标题|文章标题|
|日期|文章发布日期|
|阅读数|阅读量|
|评论数|评论数量|
|链接|文章完整链接|

---

## 注意事项
- 本脚本使用了多种备选选择器以兼容不同格式的 CSDN 页面，仍建议手动检查输出结果是否完整。

---

## 许可证
本脚本仅用于学习、研究用途，请勿用于违反 CSDN 用户协议或法律法规的行为。